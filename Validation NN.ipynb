{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#Store Data Variables\n",
    "import json\n",
    "with open('feature_data.json', 'r') as f:\n",
    " features = json.load(f)\n",
    "\n",
    "from scipy.io import loadmat\n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')['train_idx'].flatten()\n",
    "query_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')['query_idx'].flatten()\n",
    "labels = loadmat('cuhk03_new_protocol_config_labeled.mat')['labels'].flatten()\n",
    "gallery_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')['gallery_idx'].flatten()\n",
    "filelist = loadmat('cuhk03_new_protocol_config_labeled.mat')['filelist'].flatten()\n",
    "camId = loadmat('cuhk03_new_protocol_config_labeled.mat')['camId'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     3, ..., 14094, 14095, 14096], dtype=uint16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   22,    27,    49, ..., 14043, 14059, 14063], dtype=uint16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    1,    1, ..., 1467, 1467, 1467], dtype=uint16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    23,    24, ..., 14062, 14064, 14065], dtype=uint16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['1_001_1_01.png'], dtype='<U14'),\n",
       "       array(['1_001_1_02.png'], dtype='<U14'),\n",
       "       array(['1_001_1_03.png'], dtype='<U14'), ...,\n",
       "       array(['5_049_2_08.png'], dtype='<U14'),\n",
       "       array(['5_049_2_09.png'], dtype='<U14'),\n",
       "       array(['5_049_2_10.png'], dtype='<U14')], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid searc cv against k, distance metric and transformation/normalization - use only query and gallery for this part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13791114 1.12505555 0.05404324 ... 0.10747871 0.04081609 0.68009406]\n",
      " [0.02507781 0.9057585  0.00346441 ... 0.16763815 0.14764351 0.2700713 ]\n",
      " [0.09923808 1.09122825 0.01889733 ... 0.07981343 0.04958951 0.37923682]\n",
      " ...\n",
      " [0.50913167 2.1067946  1.12224829 ... 0.78767842 1.68007588 0.00259321]\n",
      " [0.44684452 1.87411916 1.51910186 ... 1.02090526 1.58616257 0.10876646]\n",
      " [0.46024311 2.31024432 1.20531154 ... 0.62753201 1.22394812 0.        ]]\n",
      "[[0.13791114 1.12505555 0.05404324 ... 0.10747871 0.04081609 0.68009406]\n",
      " [0.02507781 0.9057585  0.00346441 ... 0.16763815 0.14764351 0.2700713 ]\n",
      " [0.09923808 1.09122825 0.01889733 ... 0.07981343 0.04958951 0.37923682]\n",
      " ...\n",
      " [0.50913167 2.1067946  1.12224829 ... 0.78767842 1.68007588 0.00259321]\n",
      " [0.44684452 1.87411916 1.51910186 ... 1.02090526 1.58616257 0.10876646]\n",
      " [0.46024311 2.31024432 1.20531154 ... 0.62753201 1.22394812 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#scaler = StandardScaler()\n",
    "print(np.array(features))\n",
    "#features = scaler.fit_transform(features)\n",
    "X = np.array(features)\n",
    "print(X)\n",
    "y = np.array(labels)\n",
    "filelist = np.array(filelist)\n",
    "camId = np.array(camId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train = np.array(train_idxs).ravel()\n",
    "mask_query = np.array(query_idxs).ravel()\n",
    "mask_gallery = np.array(gallery_idxs).ravel()\n",
    "\n",
    "mask_train = np.subtract(mask_train, 1)\n",
    "mask_query = np.subtract(mask_query, 1)\n",
    "mask_gallery = np.subtract(mask_gallery, 1)\n",
    "\n",
    "\n",
    "X_train, X_query, X_gallery = X[mask_train, :], X[mask_query, :], X[mask_gallery, :]\n",
    "y_train, y_query, y_gallery = y[mask_train], y[mask_query], y[mask_gallery]\n",
    "filelist_train, filelist_query, filelist_gallery = filelist[mask_train], filelist[mask_query], filelist[mask_gallery]\n",
    "camId_train, camId_query, camId_gallery = camId[mask_train], camId[mask_query], camId[mask_gallery]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7368"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "767"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5328"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7368"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = []\n",
    "y_val = []\n",
    "camId_val = []\n",
    "val_ind = []\n",
    "for i in range(7368):\n",
    "        if(i not in val_ind):\n",
    "            X_val.append(X_train[i])\n",
    "            y_val.append(y_train[i])\n",
    "            camId_val.append(camId_train[i])\n",
    "            val_ind.append(i)\n",
    "            for j in range(7368):\n",
    "                if(y_train[i] == y_train[j] and i != j):\n",
    "                    X_val.append(X_train[j])\n",
    "                    y_val.append(y_train[j])\n",
    "                    camId_val.append(camId_train[j])\n",
    "                    val_ind.append(j)\n",
    "            if ((len(set(y_val)) > 99)):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(camId_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(val_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = []\n",
    "y_train_new = []\n",
    "camId_train_new = []\n",
    "for i in range(7368):\n",
    "    if(i not in val_ind):\n",
    "        X_train_new.append(X_train[i])\n",
    "        y_train_new.append(y_train[i])\n",
    "        camId_train_new.append(camId_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6402"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6402"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6402"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(camId_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from keras import layers, optimizers, regularizers\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.utils import plot_model\n",
    "#from kt_utils import *\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn import preprocessing, model_selection \n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "# layer 1\n",
    "model.add(Dense(6144, input_dim=6144, activation='relu', kernel_initializer='normal'))\n",
    "#layer 2\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "#layer 3\n",
    "model.add(Dense(128, activation='relu',kernel_initializer='normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "#layer 4\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# Compile model\n",
    "from keras import metrics\n",
    "optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer, loss='mean_squared_error', metrics=[metrics.mae, metrics.categorical_accuracy]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n",
      "entered\n"
     ]
    }
   ],
   "source": [
    "X_train_pairs = []\n",
    "y_train_pair_lables = []\n",
    "for Xtnn, ytnn in zip(X_val, y_val):\n",
    "    \n",
    "    randindex = random.randint(0, 100)\n",
    "    Xtnn2 = X_train[randindex]\n",
    "    ytnn2 = y_train[randindex]\n",
    "    \n",
    "    randindex = random.randint(0, 100)\n",
    "    Xtnn3 = X_train[randindex]\n",
    "    ytnn3 = y_train[randindex]                 \n",
    "    \n",
    "    if((ytnn == ytnn2) && (ytnn = ytnn2)):\n",
    "        y_train_pair_lables.append((1,1))\n",
    "    if((ytnn == ytnn2) && (ytnn != ytnn2)):\n",
    "        y_train_pair_lables.append((1,0))\n",
    "    if((ytnn != ytnn2) && (ytnn = ytnn2)):\n",
    "        y_train_pair_lables.append((0,1))\n",
    "    if((ytnn != ytnn2) && (ytnn != ytnn2)):\n",
    "        y_train_pair_lables.append((0,0))\n",
    "    \n",
    "    Xconcat = np.concatenate((Xtnn,Xtnn2,Xtnn3), axis = None)\n",
    "    X_train_pairs.append(Xconcat)\n",
    "\n",
    "y_train_pair_lables = np.array(y_train_pair_lables)\n",
    "X_train_pairs = np.array(X_train_pairs)\n",
    "model.metrics_names\n",
    "model.fit(X_train_pairs, y_train_pair_lables, batch_size=100, epochs=50)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_score(y_valid, y_q, tot_label_occur):\n",
    "    recall = 0\n",
    "    true_positives = 0\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    max_rank = 30\n",
    "    \n",
    "    rank_A = np.zeros(max_rank)\n",
    "    AP_arr = np.zeros(11)\n",
    "    \n",
    "    while (recall < 1) or (k < max_rank):\n",
    "        if (y_valid[k] == y_q):\n",
    "            \n",
    "            true_positives = true_positives + 1\n",
    "            recall = true_positives/tot_label_occur\n",
    "            precision = true_positives/(k+1)\n",
    "            \n",
    "            AP_arr[round((recall-0.05)*10)] = precision\n",
    "            \n",
    "            for n in range (k, max_rank):\n",
    "                rank_A[n] = 1\n",
    "            \n",
    "        k = k+1\n",
    "        \n",
    "    max_precision = 0\n",
    "    for i in range(10, -1, -1):\n",
    "        max_precision = max(max_precision, AP_arr[i])\n",
    "        AP_arr[i] = max_precision\n",
    "    \n",
    "    AP_ = AP_arr.sum()/11\n",
    "    \n",
    "    return AP_, rank_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def evaluate_metric(X_query, camId_query, y_query, X_gallery, camId_gallery, y_gallery, metric = mlp, parameters = None):\n",
    "\n",
    "    rank_accuracies = []\n",
    "    AP = []\n",
    "\n",
    "    # Break condition for testing\n",
    "    #q = 0\n",
    "\n",
    "    for query, camId_q, y_q in zip(X_query, camId_query, y_query):\n",
    "        q_g_dists = []\n",
    "        y_valid = []\n",
    "        for gallery, camId_g, y_g  in zip(X_gallery, camId_gallery, y_gallery):\n",
    "            if ((camId_q == camId_g) and (y_q == y_g)):\n",
    "                continue\n",
    "            else:\n",
    "                if metric == mlp:\n",
    "                    dist = model.predict(np.concatenate((query, gallery, np.zeros(2048))).reshape((1,6144)))[0][0]\n",
    "                    print(dist)\n",
    "                elif metric == 'minkowski':\n",
    "                    dist = distance.minkowski(query, gallery, parameters)\n",
    "                else:\n",
    "                    raise NameError('Specified metric not supported')           \n",
    "                q_g_dists.append(dist)\n",
    "                y_valid.append(y_g)\n",
    "    \n",
    "        tot_label_occur = y_valid.count(y_q)\n",
    "    \n",
    "        q_g_dists = np.array(q_g_dists)\n",
    "        y_valid = np.array(y_valid)\n",
    "        \n",
    "    \n",
    "        _indexes = np.argsort(q_g_dists)\n",
    "    \n",
    "        # Sorted distances and labels\n",
    "        q_g_dists, y_valid = q_g_dists[_indexes], y_valid[_indexes]\n",
    "    \n",
    "        AP_, rank_A = get_acc_score(y_valid, y_q, tot_label_occur)\n",
    "    \n",
    "        AP.append(AP_)\n",
    "        \n",
    "        rank_accuracies.append(rank_A) \n",
    "    \n",
    "        #if q  > 5:\n",
    "        #    break\n",
    "        #q = q+1\n",
    "\n",
    "    rank_accuracies = np.array(rank_accuracies)\n",
    "\n",
    "    total = rank_accuracies.shape[0]\n",
    "    rank_accuracies = rank_accuracies.sum(axis = 0)\n",
    "    rank_accuracies = np.divide(rank_accuracies, total)\n",
    "\n",
    "    i = 0\n",
    "    print ('Accuracies by Rank:')\n",
    "    while i < rank_accuracies.shape[0]:\n",
    "        print('Rank ', i+1, ' = %.2f%%' % (rank_accuracies[i] * 100), '\\t',\n",
    "              'Rank ', i+2, ' = %.2f%%' % (rank_accuracies[i+1] * 100), '\\t',\n",
    "              'Rank ', i+3, ' = %.2f%%' % (rank_accuracies[i+2] * 100), '\\t',\n",
    "              'Rank ', i+4, ' = %.2f%%' % (rank_accuracies[i+3] * 100), '\\t',\n",
    "              'Rank ', i+5, ' = %.2f%%' % (rank_accuracies[i+4] * 100))\n",
    "        i = i+5\n",
    "\n",
    "    AP = np.array(AP)\n",
    "\n",
    "    mAP = AP.sum()/AP.shape[0]\n",
    "    print('mAP = %.2f%%' % (mAP * 100))\n",
    "    \n",
    "    return rank_accuracies, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric = mlp,\n",
    "                                       parameters = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
