{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Store Data Variables\n",
    "import json\n",
    "with open('feature_data.json', 'r') as f:\n",
    " features = json.load(f)\n",
    "\n",
    "from scipy.io import loadmat\n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')['train_idx'].flatten()\n",
    "query_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')['query_idx'].flatten()\n",
    "labels = loadmat('cuhk03_new_protocol_config_labeled.mat')['labels'].flatten()\n",
    "gallery_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')['gallery_idx'].flatten()\n",
    "filelist = loadmat('cuhk03_new_protocol_config_labeled.mat')['filelist'].flatten()\n",
    "camId = loadmat('cuhk03_new_protocol_config_labeled.mat')['camId'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     3, ..., 14094, 14095, 14096], dtype=uint16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   22,    27,    49, ..., 14043, 14059, 14063], dtype=uint16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    1,    1, ..., 1467, 1467, 1467], dtype=uint16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    23,    24, ..., 14062, 14064, 14065], dtype=uint16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['1_001_1_01.png'], dtype='<U14'),\n",
       "       array(['1_001_1_02.png'], dtype='<U14'),\n",
       "       array(['1_001_1_03.png'], dtype='<U14'), ...,\n",
       "       array(['5_049_2_08.png'], dtype='<U14'),\n",
       "       array(['5_049_2_09.png'], dtype='<U14'),\n",
       "       array(['5_049_2_10.png'], dtype='<U14')], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid searc cv against k, distance metric and transformation/normalization - use only query and gallery for this part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "filelist = np.array(filelist)\n",
    "camId = np.array(camId)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train = np.array(train_idxs).ravel()\n",
    "mask_query = np.array(query_idxs).ravel()\n",
    "mask_gallery = np.array(gallery_idxs).ravel()\n",
    "\n",
    "mask_train = np.subtract(mask_train, 1)\n",
    "mask_query = np.subtract(mask_query, 1)\n",
    "mask_gallery = np.subtract(mask_gallery, 1)\n",
    "\n",
    "\n",
    "X_train, X_query, X_gallery = X[mask_train, :], X[mask_query, :], X[mask_gallery, :]\n",
    "y_train, y_query, y_gallery = y[mask_train], y[mask_query], y[mask_gallery]\n",
    "filelist_train, filelist_query, filelist_gallery = filelist[mask_train], filelist[mask_query], filelist[mask_gallery]\n",
    "camId_train, camId_query, camId_gallery = camId[mask_train], camId[mask_query], camId[mask_gallery]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_score(y_valid, y_q, tot_label_occur):\n",
    "    recall = 0\n",
    "    true_positives = 0\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    max_rank = 30\n",
    "    \n",
    "    rank_A = np.zeros(max_rank)\n",
    "    AP_arr = np.zeros(11)\n",
    "    \n",
    "    while (recall < 1) or (k < max_rank):\n",
    "        \n",
    "        if (y_valid[k] == y_q):\n",
    "            \n",
    "            true_positives = true_positives + 1\n",
    "            recall = true_positives/tot_label_occur\n",
    "            precision = true_positives/(k+1)\n",
    "            \n",
    "            AP_arr[round((recall-0.05)*10)] = precision\n",
    "            \n",
    "            for n in range (k, max_rank):\n",
    "                rank_A[n] = 1\n",
    "            \n",
    "        k = k+1\n",
    "        \n",
    "    max_precision = 0\n",
    "    for i in range(10, -1, -1):\n",
    "        max_precision = max(max_precision, AP_arr[i])\n",
    "        AP_arr[i] = max_precision\n",
    "    \n",
    "    AP_ = AP_arr.sum()/11\n",
    "    \n",
    "    return AP_, rank_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import pairwise\n",
    "\n",
    "def evaluate_metric(X_query, camId_query, y_query, X_gallery, camId_gallery, y_gallery, kernel = 'polynomial', parameters = None):\n",
    "\n",
    "    rank_accuracies = []\n",
    "    AP = []\n",
    "\n",
    "    # Break condition for testing\n",
    "    #q = 0\n",
    "\n",
    "    for query, camId_q, y_q in zip(X_query, camId_query, y_query):\n",
    "        q_g_dists = []\n",
    "        y_valid = []\n",
    "        for gallery, camId_g, y_g  in zip(X_gallery, camId_gallery, y_gallery):\n",
    "            if ((camId_q == camId_g) and (y_q == y_g)):\n",
    "                continue\n",
    "            else:\n",
    "                dist = pairwise.kernel_metrics(query, gallery)\n",
    "                if kernel == 'polynomial':\n",
    "                    dist = pairwise.polynomial_kernel(query, gallery)\n",
    "                elif kernel == 'gaussian_rbf':\n",
    "                    dist = pairwise.rbf_kernel(query, gallery)\n",
    "                elif kernel == 'sigmoid':\n",
    "                    dist = pairwise.sigmoid_kernel(query, gallery)\n",
    "                elif kernel == 'chi2':\n",
    "                    dist = pairwise.chi2_kernel(query, gallery)\n",
    "                elif kernel == 'mahalanobis':\n",
    "                    dist = distance.mahalanobis(query, gallery, parameters)\n",
    "                else:\n",
    "                    raise NameError('Specified metric not supported')\n",
    "                print (dist)\n",
    "                q_g_dists.append(dist)\n",
    "                y_valid.append(y_g)\n",
    "    \n",
    "        tot_label_occur = y_valid.count(y_q)\n",
    "    \n",
    "        q_g_dists = np.array(q_g_dists)\n",
    "        y_valid = np.array(y_valid)\n",
    "    \n",
    "        _indexes = np.argsort(q_g_dists)\n",
    "    \n",
    "        # Sorted distances and labels\n",
    "        q_g_dists, y_valid = q_g_dists[_indexes], y_valid[_indexes]\n",
    "    \n",
    "        AP_, rank_A = get_acc_score(y_valid, y_q, tot_label_occur)\n",
    "    \n",
    "        AP.append(AP_)\n",
    "        \n",
    "        rank_accuracies.append(rank_A)\n",
    "    \n",
    "        #if q  > 5:\n",
    "        #    break\n",
    "        #q = q+1\n",
    "\n",
    "    rank_accuracies = np.array(rank_accuracies)\n",
    "\n",
    "    total = rank_accuracies.shape[0]\n",
    "    rank_accuracies = rank_accuracies.sum(axis = 0)\n",
    "    rank_accuracies = np.divide(rank_accuracies, total)\n",
    "\n",
    "    i = 0\n",
    "    print ('Accuracies by Rank:')\n",
    "    while i < rank_accuracies.shape[0]:\n",
    "        print('Rank ', i+1, ' = %.2f%%' % (rank_accuracies[i] * 100), '\\t',\n",
    "              'Rank ', i+2, ' = %.2f%%' % (rank_accuracies[i+1] * 100), '\\t',\n",
    "              'Rank ', i+3, ' = %.2f%%' % (rank_accuracies[i+2] * 100), '\\t',\n",
    "              'Rank ', i+4, ' = %.2f%%' % (rank_accuracies[i+3] * 100), '\\t',\n",
    "              'Rank ', i+5, ' = %.2f%%' % (rank_accuracies[i+4] * 100))\n",
    "        i = i+5\n",
    "\n",
    "    AP = np.array(AP)\n",
    "\n",
    "    mAP = AP.sum()/AP.shape[0]\n",
    "    print('mAP = %.2f%%' % (mAP * 100))\n",
    "    \n",
    "    return rank_accuracies, mAP\n",
    "\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_accuracies_l = []\n",
    "mAP_l = []\n",
    "metric_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "kernel_metrics() got an unexpected keyword argument 'metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-539010a0c737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                        \u001b[0mX_gallery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamId_gallery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gallery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                        \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'additive_chi2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                        parameters = None)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrank_accuracies_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b241ebf2f61e>\u001b[0m in \u001b[0;36mevaluate_metric\u001b[0;34m(X_query, camId_query, y_query, X_gallery, camId_gallery, y_gallery, kernel, parameters)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'euclidian'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuclidean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: kernel_metrics() got an unexpected keyword argument 'metric'"
     ]
    }
   ],
   "source": [
    "# Baseline Euclidian\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       kernel ='additive_chi2',\n",
    "                                       parameters = None)\n",
    "\n",
    "rank_accuracies_l.append(rank_accuracies)\n",
    "mAP_l.append(mAP)\n",
    "metric_l.append('Euclidian')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies by Rank:\n",
      "Rank  1  = 47.00% \t Rank  2  = 54.57% \t Rank  3  = 59.64% \t Rank  4  = 63.93% \t Rank  5  = 66.86%\n",
      "Rank  6  = 69.29% \t Rank  7  = 71.14% \t Rank  8  = 72.36% \t Rank  9  = 73.71% \t Rank  10  = 74.93%\n",
      "Rank  11  = 75.86% \t Rank  12  = 76.79% \t Rank  13  = 77.71% \t Rank  14  = 78.50% \t Rank  15  = 79.07%\n",
      "Rank  16  = 79.86% \t Rank  17  = 80.64% \t Rank  18  = 81.57% \t Rank  19  = 82.29% \t Rank  20  = 83.21%\n",
      "Rank  21  = 83.50% \t Rank  22  = 83.71% \t Rank  23  = 84.00% \t Rank  24  = 84.29% \t Rank  25  = 84.79%\n",
      "Rank  26  = 85.29% \t Rank  27  = 85.64% \t Rank  28  = 85.93% \t Rank  29  = 86.07% \t Rank  30  = 86.36%\n",
      "mAP = 46.57%\n"
     ]
    }
   ],
   "source": [
    "# Square Euclidian\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric = 'seuclidean',\n",
    "                                       parameters = None)\n",
    "\n",
    "rank_accuracies_l.append(rank_accuracies)\n",
    "mAP_l.append(mAP)\n",
    "metric_l.append('Square Euclidian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized Euclidian\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric = 'sqeuclidean',\n",
    "                                       parameters = None)\n",
    "\n",
    "rank_accuracies_l.append(rank_accuracies)\n",
    "mAP_l.append(mAP)\n",
    "metric_l.append('Standardized Euclidian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies by Rank:\n",
      "Rank  1  = 47.21% \t Rank  2  = 54.79% \t Rank  3  = 59.86% \t Rank  4  = 63.71% \t Rank  5  = 66.14%\n",
      "Rank  6  = 68.79% \t Rank  7  = 70.29% \t Rank  8  = 72.07% \t Rank  9  = 73.79% \t Rank  10  = 75.07%\n",
      "Rank  11  = 75.93% \t Rank  12  = 77.36% \t Rank  13  = 78.43% \t Rank  14  = 79.00% \t Rank  15  = 79.79%\n",
      "Rank  16  = 80.00% \t Rank  17  = 80.57% \t Rank  18  = 81.21% \t Rank  19  = 82.29% \t Rank  20  = 82.64%\n",
      "Rank  21  = 82.93% \t Rank  22  = 83.43% \t Rank  23  = 83.86% \t Rank  24  = 84.21% \t Rank  25  = 84.50%\n",
      "Rank  26  = 84.93% \t Rank  27  = 85.36% \t Rank  28  = 85.64% \t Rank  29  = 85.93% \t Rank  30  = 86.00%\n",
      "mAP = 46.78%\n"
     ]
    }
   ],
   "source": [
    "#Manhattan Distance\n",
    "\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric = 'minkowski',\n",
    "                                       parameters = 1)\n",
    "\n",
    "rank_accuracies_l.append(rank_accuracies)\n",
    "mAP_l.append(mAP)\n",
    "metric_l.append('Manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chebyshev - L_infinity\n",
    "\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric ='chebyshev',\n",
    "                                       parameters = None)\n",
    "\n",
    "rank_accuracies_l.append(rank_accuracies)\n",
    "mAP_l.append(mAP)\n",
    "metric_l.append('Chebyshev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Braycurtis\n",
    "\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric ='braycurtis',\n",
    "                                       parameters = None)\n",
    "\n",
    "rank_accuracies_l.append(rank_accuracies)\n",
    "mAP_l.append(mAP)\n",
    "metric_l.append('Bray Curtis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canberra\n",
    "\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric ='canberra',\n",
    "                                       parameters = None)\n",
    "\n",
    "rank_accuracies_l.append(rank_accuracies)\n",
    "mAP_l.append(mAP)\n",
    "metric_l.append('Canberra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies by Rank:\n",
      "Rank  1  = 47.57% \t Rank  2  = 55.07% \t Rank  3  = 60.50% \t Rank  4  = 63.50% \t Rank  5  = 67.00%\n",
      "Rank  6  = 69.00% \t Rank  7  = 71.07% \t Rank  8  = 72.57% \t Rank  9  = 74.21% \t Rank  10  = 75.07%\n",
      "Rank  11  = 75.93% \t Rank  12  = 76.71% \t Rank  13  = 77.36% \t Rank  14  = 78.14% \t Rank  15  = 79.43%\n",
      "Rank  16  = 80.14% \t Rank  17  = 81.00% \t Rank  18  = 81.71% \t Rank  19  = 82.43% \t Rank  20  = 82.71%\n",
      "Rank  21  = 83.00% \t Rank  22  = 83.71% \t Rank  23  = 83.86% \t Rank  24  = 84.43% \t Rank  25  = 85.00%\n",
      "Rank  26  = 85.07% \t Rank  27  = 85.36% \t Rank  28  = 85.57% \t Rank  29  = 85.86% \t Rank  30  = 85.93%\n",
      "mAP = 47.21%\n"
     ]
    }
   ],
   "source": [
    "# Cosine\n",
    "\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric ='cosine',\n",
    "                                       parameters = None)\n",
    "\n",
    "rank_accuracies_l.append(rank_accuracies)\n",
    "mAP_l.append(mAP)\n",
    "metric_l.append('Cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies by Rank:\n",
      "Rank  1  = 46.93% \t Rank  2  = 54.64% \t Rank  3  = 59.71% \t Rank  4  = 63.36% \t Rank  5  = 66.36%\n",
      "Rank  6  = 68.07% \t Rank  7  = 69.79% \t Rank  8  = 71.21% \t Rank  9  = 73.07% \t Rank  10  = 74.29%\n",
      "Rank  11  = 75.07% \t Rank  12  = 76.14% \t Rank  13  = 76.93% \t Rank  14  = 77.64% \t Rank  15  = 78.29%\n",
      "Rank  16  = 79.14% \t Rank  17  = 80.07% \t Rank  18  = 80.50% \t Rank  19  = 81.57% \t Rank  20  = 82.21%\n",
      "Rank  21  = 82.79% \t Rank  22  = 83.50% \t Rank  23  = 83.64% \t Rank  24  = 84.07% \t Rank  25  = 84.21%\n",
      "Rank  26  = 84.57% \t Rank  27  = 85.14% \t Rank  28  = 85.21% \t Rank  29  = 85.64% \t Rank  30  = 86.07%\n",
      "mAP = 46.73%\n"
     ]
    }
   ],
   "source": [
    "# Correlation\n",
    "\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric ='correlation',\n",
    "                                       parameters = None)\n",
    "\n",
    "rank_accuracies_l.append(rank_accuracies)\n",
    "mAP_l.append(mAP)\n",
    "metric_l.append('Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8.0, 6.0))\n",
    "color_list = ['green', 'blue', 'red', 'purple', 'orange', 'magenta', 'cyan', 'black', 'indianred', 'lightseagreen', 'gold', 'lightgreen']\n",
    "for i in range(len(metric_l)):\n",
    "    plt.plot(np.arange(1, 31), rank_accuracies_l[i], color=color_list[i], linestyle='dashed', label='Metric: '+ metric_l[i])\n",
    "\n",
    "plt.title('CMC Curves for a range of standard distance metrics')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Recogniton Accuracy / %')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 2048)\n",
      "(7368,)\n"
     ]
    }
   ],
   "source": [
    "print (X_query.shape)\n",
    "print (y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_accuracies_l_2 = []\n",
    "mAP_l_2 = []\n",
    "metric_l_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 2048)\n",
      "(2048, 2048)\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n",
      "1 query image done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c5fdcf09bb73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                        \u001b[0mX_gallery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamId_gallery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gallery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                        \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'mahalanobis'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                        parameters = VI)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-289e7d868f30>\u001b[0m in \u001b[0;36mevaluate_metric\u001b[0;34m(X_query, camId_query, y_query, X_gallery, camId_gallery, y_gallery, metric, parameters)\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mahalanobis'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmahalanobis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Specified metric not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mmahalanobis\u001b[0;34m(u, v, VI)\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0mVI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#Mahalanobis - inverse covariance\n",
    "\n",
    "\n",
    "V = np.cov(X_train.T)\n",
    "\n",
    "print (V.shape)\n",
    "\n",
    "VI = np.linalg.inv(V)\n",
    "\n",
    "print (VI.shape)\n",
    "\n",
    "\n",
    "\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric ='mahalanobis',\n",
    "                                       parameters = VI)\n",
    "\n",
    "rank_accuracies_l_2.append(rank_accuracies)\n",
    "mAP_l_2.append(mAP)\n",
    "metric_l_2.append('Mahalanobis - Covariance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric_learn import MMC_Supervised\n",
    "\n",
    "#Mahalanobis - learnt - reduced set\n",
    "\n",
    "mmc = MMC_Supervised()\n",
    "mmc.fit(X_train[0:100], y_train[0:100])\n",
    "\n",
    "\n",
    "\n",
    "M = mmc.metric()\n",
    "\n",
    "\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric ='mahalanobis',\n",
    "                                       parameters = M)\n",
    "\n",
    "rank_accuracies_l_2.append(rank_accuracies)\n",
    "mAP_l_2.append(mAP)\n",
    "metric_l_2.append('Learnt Mahalanobis (Red. Set)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d4b7f3a28380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMMC_Supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/metric_learn/mmc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, random_state)\u001b[0m\n\u001b[1;32m    444\u001b[0m                                   random_state=random_state)\n\u001b[1;32m    445\u001b[0m     pos_neg = c.positive_negative_pairs(num_constraints,\n\u001b[0;32m--> 446\u001b[0;31m                                         random_state=random_state)\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mMMC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/metric_learn/constraints.py\u001b[0m in \u001b[0;36mpositive_negative_pairs\u001b[0;34m(self, num_constraints, same_length, random_state)\u001b[0m\n\u001b[1;32m     33\u001b[0m                               random_state=np.random):\n\u001b[1;32m     34\u001b[0m     a, b = self._pairs(num_constraints, same_label=True,\n\u001b[0;32m---> 35\u001b[0;31m                        random_state=random_state)\n\u001b[0m\u001b[1;32m     36\u001b[0m     c, d = self._pairs(num_constraints, same_label=False,\n\u001b[1;32m     37\u001b[0m                        random_state=random_state)\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/metric_learn/constraints.py\u001b[0m in \u001b[0;36m_pairs\u001b[0;34m(self, num_constraints, same_label, max_iter, random_state)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mb_choices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_choices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m           \u001b[0mab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_choices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m       \u001b[0mit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_constraints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from metric_learn import MMC_Supervised\n",
    "\n",
    "#Mahalanobis - learnt\n",
    "\n",
    "\n",
    "mmc = MMC_Supervised()\n",
    "mmc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-139c5c76023b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmahalanobis_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mmc' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "M = mmc.metric()\n",
    "\n",
    "\n",
    "rank_accuracies, mAP = evaluate_metric(X_query, camId_query, y_query,\n",
    "                                       X_gallery, camId_gallery, y_gallery,\n",
    "                                       metric ='mahalanobis',\n",
    "                                       parameters = M)\n",
    "\n",
    "rank_accuracies_l_2.append(rank_accuracies)\n",
    "mAP_l_2.append(mAP)\n",
    "metric_l_2.append('Learnt Mahalanobis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8.0, 6.0))\n",
    "color_list = ['green', 'blue', 'red', 'purple', 'orange', 'magenta', 'cyan', 'black', 'indianred', 'lightseagreen', 'gold', 'lightgreen']\n",
    "for i in range(len(metric_l_2)):\n",
    "    plt.plot(np.arange(1, 31), rank_accuracies_l_2[i], color=color_list[i], linestyle='dashed', label='Metric: '+ metric_l_2[i])\n",
    "\n",
    "plt.title('CMC Curves for a range of standard distance metrics')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Recogniton Accuracy / %')\n",
    "plt.legend(loc='best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
